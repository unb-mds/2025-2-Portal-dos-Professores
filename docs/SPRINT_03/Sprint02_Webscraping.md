# DecisÃµes TÃ©cnicas Iniciais: Coleta e Processamento de Dados

Este documento resume as decisÃµes tomadas em relaÃ§Ã£o Ã s tecnologias de Web Scraping e SumarizaÃ§Ã£o por InteligÃªncia Artificial para o projeto "Portal de Professores da UnB".

## 1. Contexto e Objetivos

O projeto necessita de um processo automatizado para:
1.  **Coletar** informaÃ§Ãµes pÃºblicas de docentes de fontes como Lattes, Sigaa e Google Scholar.
2.  **Processar** os dados coletados para gerar um resumo qualitativo sobre a atuaÃ§Ã£o de cada professor.
3.  **Operar** de forma eficiente e confiÃ¡vel dentro de uma arquitetura serverless em workflows do GitHub Actions.

Para atender a esses requisitos, realizamos uma anÃ¡lise de ferramentas para cada etapa do processo.

## 2. Escolha da Ferramenta de Web Scraping

Analisamos diversas bibliotecas Python, com foco na capacidade de lidar com sites modernos e na viabilidade de execuÃ§Ã£o no ambiente do GitHub Actions.

### Tabela Comparativa de Ferramentas de Scraping

| Ferramenta | PrÃ³s | Contras | Viabilidade em GitHub Actions |
| :--- | :--- | :--- | :--- |
| **Requests + BS4** | ğŸ”¹ Leve e rÃ¡pido<br>ğŸ”¹ Simples de usar | ğŸ”¸ **NÃ£o executa JavaScript**<br>ğŸ”¸ Ineficaz para sites dinÃ¢micos | **Limitada** |
| **Selenium** | ğŸ”¹ PadrÃ£o de mercado<br>ğŸ”¹ Robusto e confiÃ¡vel | ğŸ”¸ Mais lento que Playwright<br>ğŸ”¸ API mais verbosa | **Excelente** |
| â­ **Playwright** | ğŸ”¹ **RÃ¡pido e moderno**<br>ğŸ”¹ API limpa com suporte `async`<br>ğŸ”¹ **Setup simplificado** | ğŸ”¸ Curva de aprendizado um pouco maior que o bÃ¡sico | **Excelente (Recomendado)** |

### DecisÃ£o: Playwright

A biblioteca **Playwright** foi a escolhida. Sua performance superior, API moderna e, principalmente, sua facilidade de configuraÃ§Ã£o em ambientes de CI/CD como o GitHub Actions a tornam a soluÃ§Ã£o ideal para garantir uma coleta de dados robusta e eficiente.

## 3. Escolha da Ferramenta de SumarizaÃ§Ã£o por IA

A sumarizaÃ§Ã£o dos dados coletados Ã© um requisito chave. Avaliamos duas abordagens principais: rodar um modelo de IA localmente no runner do GitHub Actions ou utilizar uma API externa.

### Tabela Comparativa de Abordagens de SumarizaÃ§Ã£o

| Abordagem | PrÃ³s | Contras | Viabilidade em GitHub Actions |
| :--- | :--- | :--- | :--- |
| **Modelo Local (Hugging Face)** | ğŸ”¹ Sem custo de API<br>ğŸ”¹ Controle total | ğŸ”¸ **Alto consumo de CPU/RAM**<br>ğŸ”¸ Lento, aumenta o tempo do workflow<br>ğŸ”¸ Risco de falhas por limite de recursos | **Baixa** |
| â­ **API Externa (Google Gemini)** | ğŸ”¹ **Leve e rÃ¡pido para o runner**<br>ğŸ”¹ Resumos de altÃ­ssima qualidade<br>ğŸ”¹ **ImplementaÃ§Ã£o simples**<br>ğŸ”¹ Custo zero para a escala do projeto | ğŸ”¸ DependÃªncia externa<br>ğŸ”¸ Requer gerenciamento de chaves de API | **Excelente (Recomendado)** |

### DecisÃ£o: API do Google Gemini

Optamos por utilizar a **API do Google Gemini**. Esta abordagem delega o processamento pesado de IA para um serviÃ§o especializado, mantendo nosso workflow no GitHub Actions extremamente rÃ¡pido, leve e confiÃ¡vel. A qualidade dos resumos Ã© excelente e a cota de uso gratuito Ã© mais do que suficiente para as necessidades do projeto.

## 4. Documento de DecisÃ£o Arquitetural (ADR)

Para formalizar estas escolhas, foi redigido o seguinte Architecture Decision Record (ADR).

---

### ADR-001: Escolha de Ferramentas para Coleta de Dados e SumarizaÃ§Ã£o por IA

* **Status:** `Accepted`

* **Context:** O projeto "Portal de Professores da UnB" necessita de um processo automatizado para coletar dados de fontes web e gerar resumos qualitativos por IA. Este processo deve operar em uma arquitetura serverless (GitHub Actions), sendo robusto para sites dinÃ¢micos e eficiente com os recursos disponÃ­veis.

* **Decision:**
    1.  Para web scraping, utilizaremos a biblioteca **Playwright**.
    2.  Para a geraÃ§Ã£o dos resumos por IA, utilizaremos a **API do Google Gemini**.

* **Consequences:**
    * **Positivas:**
        * Capacidade de extrair dados de sites complexos e dinÃ¢micos.
        * Workflow de dados rÃ¡pido e eficiente no GitHub Actions.
        * Alta qualidade nos resumos gerados com implementaÃ§Ã£o simplificada.
        * ManutenÃ§Ã£o do "backend" focada em scripts Python, sem a complexidade de gerenciar modelos de IA.
    * **Negativas:**
        * Introduz uma dependÃªncia externa (API do Google Gemini).
        * Exige o gerenciamento seguro de chaves de API atravÃ©s do GitHub Secrets.
        * Potencial de custo futuro em caso de expansÃ£o massiva do projeto.

---